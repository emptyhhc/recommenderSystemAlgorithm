**1、什么是KNN算法**  
KNN算法全称为K近邻算法，是一种分类算法。给定一个类别已定的数据集，对于新的数据，根据距离其最近的k个点来分类。k近邻实际上是利用训练数据对特征向量空间进行划分。当k=1时，叫做最近邻方法。 

**2、KNN算法的三要素**
* k值大小
* 距离度量
* 分类决策规则  
  
通常来讲k使用交叉验证来确定；距离度量使用欧式距离或p范数；分类决策规则为投票。

**3、k值选择**  
k值如果过小，意味着对临近点数据比较敏感，这时如果是噪声的话，影响比较大，容易造成过拟合。k值如果过大的话，较远的点也会起作用，增加了预测错误的概率。  
k值小的话，估计误差会增大；k值大的话近似误差会增大。

**4、什么是kd树**  
kd树是一棵二叉树，它是将k维特征向量空间进行划分并进行快速检索的一种数据结构。

**5、kd树的构造**  
通常从k维特征中的第一维开始，选择该维特征的中位数为切分点，使用该点将空间切分为垂直于该坐标轴的2个空间；接着k维特征轮流进行切分，知道无法切分为止。  

优化点：  
在按维度切分时，不轮流，而是计算k维特征的方差，选择方差大的进行切分，目的是确保数据尽可能分散。

**6、kd数搜索**  
先根据kd数进行搜索，直到达到某个小区域。此时计算该区域下的点和待搜索点的距离，并以此距离画圆。当其他区域与这个圆相交时，说明其他区域也存在着更小距离的点，就去其他区域查找，对比距离。