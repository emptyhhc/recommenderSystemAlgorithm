**1、损失函数**  
损失函数是用来度量模型预测错误程度的，在链式法则的梯度下降中无用。常用来对比不同模型在同一数据集下的效果好坏，以及用来判断模型是否收敛，从而停止训练。

**2、MSE损失函数**  
MSE中 (y_true - y_predict)**2, y_true在前，在链式法则中求偏导时无需确保其为正。

**3、经验风险和结构化风险**  
经验风险是指训练集中样本的平均损失，而结构化风险是指模型本身的风险。结构风险最小化等价与正则化，是为了防止过拟合现象。求解最优模型就是最小化经验风险和结构化风险，即$\min \frac{1}{N} \sum_{i=1}^{N} L(y_i, f(x_i)) + \lambda J(f)$，其中加号前面是经验风险、后面是模型复杂度，也就是结构化风险，$\lambda$是系数，用来平衡二者。

**4、正则化**  
正则化是为了抑制过拟合现象，L1、L2正则化分别对应贝叶斯网络的拉普拉斯先验分布和高斯先验分布。  

L1正则化：  

$L(w) = \frac{1}{N}\sum_{i=1}^N(f(x_i;w)^2-y_i)^2+\lambda\lVert w\rVert_1$

L1正则化会减少参数量，让参数尽可能为0，使模型更加简洁

L2正则化:

$L(w) = \frac{1}{N}\sum_{i=1}^N(f(x_i;w)^2-y_i)^2+\frac{\lambda}{2}\lVert w\rVert^2$

L2正则化会使参数值变小，尽可能平缓

**5、精确率和召回率**

分类器分类结果分为4类

* TP：将正类预测为正类  
* FN：将正类预测为负类  
* TN：将负类预测为负类  
* FP：将负类预测为正类

精确率(precision) 为测试集中预测正确的正例比预测为正例的样本数

$P = \frac{TP}{TP+FP}$

召回率(recall)为测试集中预测正确的正例数比真实正例数

$R = \frac{TP}{TP+FN}$

F1值为精确率和召回率的调和均值

$F1 = \frac{1}{\frac{\frac{1}{P}+\frac{1}{R}}{2}} = \frac{2PR}{P+R}$
